# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

Zenn CLIã‚’ä½¿ç”¨ã—ãŸæŠ€è¡“è¨˜äº‹ã¨æ›¸ç±ã®åŸ·ç­†ãƒ»ç®¡ç†ãƒªãƒã‚¸ãƒˆãƒªã§ã™ã€‚è¨˜äº‹ã¯Markdownå½¢å¼ã§`articles/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã•ã‚Œã€Zenn.devã«å…¬é–‹ã•ã‚Œã¾ã™ã€‚

## é–‹ç™ºã‚³ãƒãƒ³ãƒ‰

### Zenn CLI ã‚³ãƒãƒ³ãƒ‰

```bash
# æ–°ã—ã„è¨˜äº‹ã‚’ä½œæˆ
npx zenn new:article
# ã¾ãŸã¯
make article

# æ–°ã—ã„æœ¬ã‚’ä½œæˆ
npx zenn new:book
# ã¾ãŸã¯
make book

# è¨˜äº‹ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ï¼‰
npx zenn preview
```

### ãƒªãƒ³ãƒˆãƒ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

```bash
# textlintå®Ÿè¡Œï¼ˆæ—¥æœ¬èªæ–‡ç« ã®æ ¡æ­£ï¼‰
bun run textlint ./articles

# Biomeå®Ÿè¡Œï¼ˆTypeScript/JavaScriptã‚³ãƒ¼ãƒ‰ï¼‰
npx biome check

# dprintå®Ÿè¡Œï¼ˆã‚³ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
npx dprint check
```

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```tree
.
â”œâ”€â”€ articles/           # Zennè¨˜äº‹ï¼ˆMarkdownãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
â”‚   â””â”€â”€ *.md           # è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚¹ãƒ©ãƒƒã‚°å.mdï¼‰
â”œâ”€â”€ images/            # è¨˜äº‹ç”¨ç”»åƒ
â”‚   â””â”€â”€ {slug}/        # å„è¨˜äº‹ã®ã‚¹ãƒ©ãƒƒã‚°åã§ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
â”œâ”€â”€ src/               # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚„ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ .textlintrc        # textlintè¨­å®šï¼ˆæ—¥æœ¬èªæ–‡ç« æ ¡æ­£ï¼‰
â”œâ”€â”€ biome.json         # Biomeè¨­å®šï¼ˆã‚³ãƒ¼ãƒ‰ãƒªãƒ³ãƒˆï¼‰
â”œâ”€â”€ dprint.json        # dprintè¨­å®šï¼ˆã‚³ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
â””â”€â”€ Makefile           # ã‚ˆãä½¿ã†ã‚³ãƒãƒ³ãƒ‰ã®ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ
```

## ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„

### TypeScript/JavaScript (src/)

Biomeã®è¨­å®šã«å¾“ã†ï¼š

- ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆ: 4ã‚¹ãƒšãƒ¼ã‚¹ï¼ˆã‚¿ãƒ–æ–‡å­—ä½¿ç”¨ï¼‰
- è¡Œå¹…: 80æ–‡å­—
- ã‚»ãƒŸã‚³ãƒ­ãƒ³: å¿…é ˆ
- ã‚¯ã‚©ãƒ¼ãƒˆ: ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆ
- é…åˆ—å‹: shorthandè¨˜æ³• (`Type[]`)

dprintè¨­å®šã‚‚é©ç”¨ã•ã‚Œã‚‹ï¼š

- ã‚¿ãƒ–ã‚’ä½¿ç”¨
- æ”¹è¡Œ: LF
- ãƒ–ãƒ¬ãƒ¼ã‚¹ä½ç½®: same line unless hanging

### Markdownè¨˜äº‹ (articles/)

è¨˜äº‹ã®ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼š

```yaml
---
title: "è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«"
emoji: "ğŸ“"
type: "tech"  # techã¾ãŸã¯idea
topics: ["javascript", "typescript"]  # ã‚¿ã‚°
published: true  # ã¾ãŸã¯ false
---
```

textlintãƒ«ãƒ¼ãƒ«ï¼š

- æ–‡ä½“: æœ¬æ–‡ã¯ã€Œã§ã™ã¾ã™èª¿ã€ã€ãƒªã‚¹ãƒˆã¯ã€Œã§ã‚ã‚‹èª¿ã€
- æœ€å¤§æ–‡é•·: 150æ–‡å­—
- ã‚³ãƒ¼ãƒ‰å‰å¾Œã«åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’å…¥ã‚Œã‚‹
- åŠè§’ã¨å…¨è§’ã®é–“ã«ã‚¹ãƒšãƒ¼ã‚¹ã‚’å…¥ã‚Œãªã„

### ç”»åƒã®é…ç½®

è¨˜äº‹ã«ç”»åƒã‚’ä½¿ç”¨ã™ã‚‹å ´åˆï¼š

1. `images/`ç›´ä¸‹ã«è¨˜äº‹ã®ã‚¹ãƒ©ãƒƒã‚°åã§ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
2. ãã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã«ç”»åƒã‚’é…ç½®
3. è¨˜äº‹å†…ã§ã¯ç›¸å¯¾ãƒ‘ã‚¹ã§å‚ç…§

ä¾‹: `images/44e6ed7d381304/screenshot.png`

## CI/CD

`.github/workflows/run-textlint.yml`ã§Pull Requestæ™‚ã«textlintãŒè‡ªå‹•å®Ÿè¡Œã•ã‚Œã€å•é¡ŒãŒã‚ã‚Œã°ã‚³ãƒ¡ãƒ³ãƒˆã§å ±å‘Šã•ã‚Œã¾ã™ã€‚

## ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼

Bunã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ï¼š

```bash
# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
bun install

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
bun run <script-name>
```

## è¨˜äº‹ä¿®æ­£ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‡ºã—æ–¹

1. ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒ•ã‚©ãƒ¼ã‚¯
2. ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆ
3. è¨˜äº‹ã‚’ç·¨é›†
4. Pull Requestã‚’ä½œæˆ

Pull Requestæ™‚ã«textlintãŒè‡ªå‹•å®Ÿè¡Œã•ã‚Œã€æ—¥æœ¬èªã®æ–‡ç« å“è³ªãŒãƒã‚§ãƒƒã‚¯ã•ã‚Œã¾ã™ã€‚

<h1 align=center>mitata</h1>
<div align=center>benchmark tooling that loves you â¤ï¸</div>
<br />

<div align="center">
  <img width=68% src="https://raw.githubusercontent.com/evanwashere/mitata/master/.github/readme.gif"></img>
</div>

<br />

### Install

`bun add mitata`

`npm install mitata`

try mitata in browser with ai assistant at [https://bolt.new/~/mitata](https://bolt.new/~/mitata)

## Recommendations

- use dedicated hardware for running benchmarks
- read [writing good benchmarks](#writing-good-benchmarks) & [LLVM benchmarking tips](https://llvm.org/docs/Benchmarking.html)
- run with manual garbage collection enabled (e.g. `node --expose-gc ...`)
- install optional [hardware counters](#hardware-counters) extension to see cpu stats like IPC (instructions per cycle)
- make sure your runtime has high-resolution timers and other relevant options/permissions enabled

## Quick Start

<table>
<tr>
<th>javascript</th>
<th>c++ single header</th>
</tr>
<tr>
<td>

```js
import { run, bench, boxplot, summary } from 'mitata';

function fibonacci(n) {
  if (n <= 1) return n;
  return fibonacci(n - 1) + fibonacci(n - 2);
}

bench('fibonacci(40)', () => fibonacci(40));

boxplot(() => {
  summary(() => {
    bench('Array.from($size)', function* (state) {
      const size = state.get('size');
      yield () => Array.from({ length: size });
    }).range('size', 1, 1024);
  });
});

await run();
```

</td>
<td>

```cpp
#include "src/mitata.hpp"

int fibonacci(int n) {
  if (n <= 1) return n;
  return fibonacci(n - 1) + fibonacci(n - 2);
}

int main() {
  mitata::runner runner;
  runner.bench("noop", []() { });

  runner.summary([&]() {
    runner.bench("empty fn", []() { });
    runner.bench("fibonacci", []() { fibonacci(20); });
  });

  auto stats = runner.run();
}
```

</td>
</tr>
</table>

## configure your experience

```js
import { run } from 'mitata';

await run({ format: 'json' }) // output json
await run({ filter: /new Array.*/ }) // only run benchmarks that match regex filter
await run({ throw: true }); // will immediately throw instead of handling error quietly
await run({ format: { mitata: { name: 'fixed' } } }); // benchmarks name column is fixed length

// c++
auto stats = runner.run({ .colors = true, .format = "json", .filter = std::regex(".*") });
```

## garbage collection

By default, on runtimes with exposed manual gc (like bun or node with `--expose-gc`), mitata runs garbage collection once after each benchmark warmup.

This behavior can be customized using `gc(mode)` method on benchmarks:

```js
bench('lots of allocations', () => {
  Array.from({ length: 1024 }, () => Array.from({ length: 1024 }, () => new Array(1024)));
})
  // mode: false | 'once' (default) | 'inner'

  // once mode runs gc after warmup
  // inner mode runs gc after warmup and before each (batch-)iteration
  .gc('inner');
```

### gc impact and memory usage

For runtimes that provide manual garbage collection or offer access to javscript vm heap usage metrics, additional row will be shown with garbage collection timings or/and estimated heap usage.

```js
------------------------------------------- -------------------------------
new Array(512)               509.42 ns/iter 536.53 ns  â–…â–ƒâ–ˆ      â–‚
                    (449.52 ns â€¦ 632.54 ns) 609.34 ns  â–ˆâ–ˆâ–ˆ   â–ƒâ–…â–†â–ˆâ–‡
                    (  0.00  b â€¦  24.00 kb)   1.61 kb â–†â–ˆâ–ˆâ–ˆâ–ˆâ–…â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–…â–…â–ˆâ–…â–„â–‚â–‚

Array.from(512)                1.29 Âµs/iter   1.30 Âµs  â–‚â–†â–ˆ
                        (1.27 Âµs â€¦ 1.48 Âµs)   1.40 Âµs â–‚â–ˆâ–ˆâ–ˆâ–‡â–†â–ƒâ–ƒâ–‚â–â–â–‚â–â–â–â–â–â–â–â–â–
                  gc(457.25 Âµs â€¦ 760.54 Âµs) 512.32  b (  0.00  bâ€¦ 84.00 kb)
```

## universal compatibility

Out of box mitata can detect engine/runtime it's running on and fall back to using [alternative](https://github.com/evanwashere/mitata/blob/master/src/lib.mjs#L51) non-standard I/O functions. If your engine or runtime is missing support, open an issue or pr requesting for support.

### how to use mitata with engine CLIs like d8, jsc, graaljs, spidermonkey

```bash
xs bench.mjs
quickjs bench.mjs
d8 --expose-gc bench.mjs
spidermonkey -m bench.mjs
graaljs --js.timer-resolution=1 bench.mjs
/System/Library/Frameworks/JavaScriptCore.framework/Versions/Current/Helpers/jsc bench.mjs
```

```js
// bench.mjs

import { print } from './src/lib.mjs';
import { run, bench } from './src/main.mjs'; // git clone
import { run, bench } from './node_modules/mitata/src/main.mjs'; // npm install

print('hello world'); // works on every engine
```

## adding arguments and parameters to your benchmarks has never been so easy

With other benchmarking libraries, often it's quite hard to easily make benchmarks that go over a range or run the same function with different arguments without writing spaghetti code, but now with mitata converting your benchmark to use arguments is just a function call away.

```js
import { bench } from 'mitata';

bench(function* look_mom_no_spaghetti(state) {
  const len = state.get('len');
  const len2 = state.get('len2');
  yield () => new Array(len * len2);
})

.args('len', [1, 2, 3])
.range('len', 1, 1024) // 1, 8, 64, 512...
.dense_range('len', 1, 100) // 1, 2, 3 ... 99, 100
.args({ len: [1, 2, 3], len2: ['4', '5', '6'] }) // every possible combination
```

### computed parameters

For cases where you need unique copy of value for each iteration, mitata supports creating computed parameters that do not count towards benchmark results *(note: there is no guarantee of recompute time, order, or call count)*:

```js
bench('deleting $keys from object', function* (state) {
  const keys = state.get('keys');

  const obj = {};
  for (let i = 0; i < keys; i++) obj[i] = i;

  yield {
    [0]() {
      return { ...obj };
    },

    bench(p0) {
      for (let i = 0; i < keys; i++) delete p0[i];
    },
  };
}).args('keys', [1, 10, 100]);
```

### concurrency

`concurrency` option enables transparent concurrent execution of asynchronous benchmark, providing insights into:

- scalability of async functions
- potential bottlenecks in parallel code
- performance under different levels of concurrency

(note: concurrent benchmarks may have higher variance due to scheduling, contention, event loop and async overhead)

```js
bench('sleepAsync(1000) x $concurrency', function* () {
  // concurrency inherited from arguments
  yield async () => await sleepAsync(1000);
}).args('concurrency', [1, 5, 10]);

bench('sleepAsync(1000) x 5', function* () {
  yield {
    // concurrency is set manually
    concurrency: 5,

    async bench() {
      await sleepAsync(1000);
    },
  };
});
```

## hardware counters

`bun add @mitata/counters`

`npm install @mitata/counters`

supported on: `macos (apple silicon) | linux (amd64, aarch64)`

linux:

- `/proc/sys/kernel/perf_event_paranoid` has to be set to `2` or lower
- on some vm systems pmu is disabled by hypervisor (usually when cpu core is shared across vms)

macos:

- [Apple Silicon CPU optimization guide/handbook](https://developer.apple.com/documentation/apple-silicon/cpu-optimization-guide)
- Xcode must be installed for complete cpu counters support
- Instruments.app (CPU Counters) has to be closed during benchmarking
- Corrupted install of Xcode/Command Line Tools can result in kernel panic (requires Xcode/Command Line Tools reinstall)

By installing `@mitata/counters` package you can enable collection and displaying of hardware counters for benchmarks.

```rust
------------------------------------------- -------------------------------
new Array(1024)              332.67 ns/iter 337.90 ns   â–ˆ
                    (295.63 ns â€¦ 507.93 ns) 455.66 ns â–‚â–ˆâ–ˆâ–‡â–„â–‚â–‚â–‚â–â–‚â–â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–
                  2.41 ipc ( 48.66% stalls)  37.89% L1 data cache
          1.11k cycles   2.69k instructions  33.09% retired LD/ST ( 888.96)

new URL(google.com)          246.40 ns/iter 245.10 ns       â–ˆâ–ƒ
                    (206.01 ns â€¦ 841.23 ns) 302.39 ns â–â–â–â–â–‚â–ˆâ–ˆâ–ˆâ–‡â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
                  4.12 ipc (  1.05% stalls)  98.88% L1 data cache
         856.49 cycles   3.53k instructions  28.65% retired LD/ST (  1.01k)
```

## helpful warnings

For those who love doing micro-benchmarks, mitata can automatically detect and inform you about optimization passes like dead code elimination without requiring any special engine flags.

```rust
-------------------------------------- -------------------------------
1 + 1                   318.63 ps/iter 325.37 ps        â–‡  â–ˆ           !
                (267.92 ps â€¦ 14.28 ns) 382.81 ps â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–â–â–
empty function          319.36 ps/iter 325.37 ps          â–ˆ â–…          !
                (248.62 ps â€¦ 46.61 ns) 382.81 ps â–â–â–â–â–â–â–ƒâ–â–â–ˆâ–â–ˆâ–‡â–â–â–â–â–â–â–â–

! = benchmark was likely optimized out (dead code elimination)
```

## powerful visualizations right in your terminal

With mitataâ€™s ascii rendering capabilities, now you can easily visualize samples in barplots, boxplots, lineplots, histograms, and get clear summaries without any additional tools or dependencies.

```js
import { summary, barplot, boxplot, lineplot } from 'mitata';

// wrap bench() calls in visualization scope
barplot(() => {
  bench(...)
});

                        â”Œ                                            â”
                  1 + 1 â”¤â–  318.11 ps
             Date.now() â”¤â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â–  27.69 ns
                        â””                                            â”˜

// scopes can be async
await boxplot(async () => {
  // ...
});

                        â”Œ                                            â”
                                        â•·â”Œâ”€â”¬â”€â”                       â•·
            Bubble Sort                 â”œâ”¤ â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                        â•µâ””â”€â”´â”€â”˜                       â•µ
                        â”¬   â•·
             Quick Sort â”‚â”€â”€â”€â”¤
                        â”´   â•µ
                        â”¬
            Native Sort â”‚
                        â”´
                        â””                                            â”˜
                        90.88 Âµs            2.43 ms            4.77 ms

// can combine multiple visualizations
lineplot(() => {
  summary(() => {
    // ...
  });

  // bench() calls here wont be part of summary
});

summary
  new Array($len)
   5.42â€¦8.33x faster than Array.from($len)

                        â”Œ                                            â”
      Array.from($size)                                            â¢ â Š
       new Array($size)                                          â¢€â ”â 
                                                                â¡ â ƒ
                                                              â¢€â 
                                                             â¡”â 
                                                           â¡ â Š
                                                         â¢€â œ
                                                        â¡ â ƒ
                                                       â¡”â 
                                                     â¢€â 
                                                    â¡ â ƒ
                                                  â¢€â œ
                                                 â¢ â Š             â£€â£€â ¤â ¤â ’
                                                â¡°â        â£€â¡ â ¤â ”â ’â Šâ ‰
                                           â£€â£€â£€â ¤â œ   â£€â¡ â ¤â ’â Šâ ‰
                         â£¤â£¤â£¤â£¤â£¤â£¤â£¤â£¤â£¤â£¤â£¤â£¤â£”â£’â£’â£Šâ£‰â ­â ¤â ¤â ¤â ¤â ¤â ’â Šâ ‰
                        â””                                            â”˜
```

## give your own code power of mitata

In case you donâ€™t need all the fluff that comes with mitata or just need raw results, mitata exports its fundamental building blocks to allow you to easily build your own tooling and wrappers without losing any core benefits of using mitata.

```cpp
#include "src/mitata.hpp"

int main() {
  auto stats = mitata::lib::fn([]() { /***/ })
}
```

```js
import { B, measure } from 'mitata';

// lowest level for power users
const stats = await measure(function* (state) {
  const size = state.get('x');

  yield {
    [0]() {
      return size;
    },

    bench(size) {
      return new Array(size);
    },
  };
}, {
  args: { x: 1 },
  batch_samples: 5 * 1024,
  min_cpu_time: 1000 * 1e6,
});

// explore how magic happens
console.log(stats.debug) // -> jit optimized source code of benchmark

// higher level api that includes mitata's argument and range features
const b = new B('new Array($x)', function* (state) {
  const size = state.get('x');
  yield () => new Array(size);
}).args('x', [1, 5, 10]);

const trial = await b.run();
```

## accuracy down to picoseconds

By leveraging the power of javascript JIT compilation, mitata is able to generate zero-overhead measurement loops that provide picoseconds precision in timing measurements. These loops are so precise that they can even be reused to provide additional features like CPU clock frequency estimation and dead code elimination detection, all while staying inside javascript vm sandbox.

With [computed parameters](#computed-parameters) and [garbage collection tuning](#garbage-collection), you can tap into mitata's code generation capabilities to further refine the accuracy of your benchmarks. Using computed parameters ensures that parameters computation is moved outside the benchmark, thereby preventing the javascript JIT from performing loop invariant code motion optimization.

```rust
// node --expose-gc --allow-natives-syntax tools/compare.mjs
clk: ~2.71 GHz
cpu: Apple M2 Pro
runtime: node 23.3.0 (arm64-darwin)

benchmark                   avg (min â€¦ max) p75   p99    (min â€¦ top 1%)
------------------------------------------- -------------------------------
a / b                          4.59 ns/iter   4.44 ns â–ˆ
                       (4.33 ns â€¦ 25.86 ns)   6.91 ns â–ˆâ–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
                  6.70 ipc (  2.17% stalls)    NaN% L1 data cache
          16.80 cycles  112.52 instructions   0.00% retired LD/ST (   0.00)

a / b (computed)               4.23 ns/iter   4.10 ns â–‡â–ˆ
                       (3.88 ns â€¦ 30.03 ns)   7.26 ns â–ˆâ–ˆâ–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
                  6.40 ipc (  2.10% stalls)    NaN% L1 data cache
          15.70 cycles  100.53 instructions   0.00% retired LD/ST (   0.00)
4.59 ns/iter - https://npmjs.com/mitata

// vs other libraries

a / b x 90,954,882 ops/sec Â±2.13% (92 runs sampled)
10.99 ns/iter - https://npmjs.com/benchmark

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ (index) â”‚ Task name â”‚ Latency average (ns) â”‚ Latency median (ns) â”‚ Throughput average (ops/s) â”‚ Throughput median (ops/s) â”‚ Samples  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0       â”‚ 'a / b'   â”‚ '27.71 Â± 0.09%'      â”‚ '41.00'             â”‚ '28239766 Â± 0.01%'         â”‚ '24390243'                â”‚ 36092096 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
27.71 ns/iter - vitest bench / https://npmjs.com/tinybench

a / b x 86,937,932 ops/sec (11 runs sampled) v8-never-optimize=true min..max=(11.32ns...11.62ns)
11.51 ns/iter - https://npmjs.com/bench-node

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Slower tests â”‚ Samples â”‚             Result â”‚ Tolerance â•‘
â•Ÿâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¢
â•‘ Fastest test â”‚ Samples â”‚             Result â”‚ Tolerance â•‘
â•Ÿâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¢
â•‘ a / b        â”‚   10000 â”‚ 14449822.99 op/sec â”‚  Â± 4.04 % â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•
69.20 ns/iter - https://npmjs.com/cronometro
```

<details>
<summary>same test with v8 jit compiler disabled:</summary>

```rust
// node --expose-gc --allow-natives-syntax --jitless tools/compare.mjs
clk: ~0.06 GHz
cpu: Apple M2 Pro
runtime: node 23.3.0 (arm64-darwin)

benchmark                   avg (min â€¦ max) p75   p99    (min â€¦ top 1%)
------------------------------------------- -------------------------------
a / b                         74.52 ns/iter  75.53 ns â–ˆ
                     (71.96 ns â€¦ 104.94 ns)  92.01 ns â–ˆâ–…â–‡â–…â–…â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
                  5.78 ipc (  0.51% stalls)    NaN% L1 data cache
         261.51 cycles   1.51k instructions   0.00% retired LD/ST (   0.00)

a / b (computed)              56.05 ns/iter  57.20 ns â–ˆ
                      (53.62 ns â€¦ 84.69 ns)  73.21 ns â–ˆâ–…â–†â–…â–…â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
                  5.65 ipc (  0.59% stalls)    NaN% L1 data cache
         197.74 cycles   1.12k instructions   0.00% retired LD/ST (   0.00)
74.52 ns/iter - https://npmjs.com/mitata

// vs other libraries

a / b x 11,232,032 ops/sec Â±0.50% (99 runs sampled)
89.03 ns/iter - https://npmjs.com/benchmark

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ (index) â”‚ Task name â”‚ Latency average (ns) â”‚ Latency median (ns) â”‚ Throughput average (ops/s) â”‚ Throughput median (ops/s) â”‚ Samples â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0       â”‚ 'a / b'   â”‚ '215.53 Â± 0.08%'     â”‚ '208.00'            â”‚ '4786095 Â± 0.01%'          â”‚ '4807692'                 â”‚ 4639738 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
215.53 ns/iter - vitest bench / https://npmjs.com/tinybench

a / b x 10,311,999 ops/sec (11 runs sampled) v8-never-optimize=true min..max=(95.66ns...97.51ns)
96.86 ns/iter - https://npmjs.com/bench-node

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Slower tests â”‚ Samples â”‚            Result â”‚ Tolerance â•‘
â•Ÿâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¢
â•‘ Fastest test â”‚ Samples â”‚            Result â”‚ Tolerance â•‘
â•Ÿâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¢
â•‘ a / b        â”‚    2000 â”‚ 4664908.00 op/sec â”‚  Â± 0.94 % â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•
214.37 ns/iter - https://npmjs.com/cronometro
```

</details>

## writing good benchmarks

Creating accurate and meaningful benchmarks requires careful attention to how modern JavaScript engines optimize code. This covers essential concepts and best practices to ensure your benchmarks measure actual performance characteristics rather than optimization artifacts.

### examples

- [readme gif](/examples/gif.js)
- [cpu cache line size](/examples/cacheline.js)
- [holey vs packed arrays](/examples/holey_array.js)

### dead code elimination

JIT can detect and eliminate code that has no observable effects. To ensure your benchmark code executes as intended, you must create observable side effects.

```js
import { do_not_optimize } from 'mitata';

bench(function* () {
  // âŒ Bad: jit can see that function has zero side-effects
  yield () => new Array(0);
  // will get optimized to:
  /*
    yield () => {};
  */

  // âœ… Good: do_not_optimize(value) emits code that causes side-effects
  yield () => do_not_optimize(new Array(0));
});
```

### garbage collection pressure

For benchmarks involving significant memory allocations, controlling garbage collection frequency can improve results consistency.

```js
// âŒ Bad: unpredictable gc pauses
bench(() => {
  const bigArray = new Array(1000000);
});

// âœ… Good: gc before each (batch-)iteration
bench(() => {
  const bigArray = new Array(1000000);
}).gc('inner'); // run gc before each iteration
```

### loop invariant code motion optimization

JavaScript engines can optimize away repeated computations by hoisting them out of loops or caching results. Use computed parameters to prevent loop invariant code motion optimization.

```js
bench(function* (ctx) {
  const str = 'abc';

  // âŒ Bad: JIT sees that both str and 'c' search value are constants/comptime-known
  yield () => str.includes('c');
  // will get optimized to:
  /*
    yield () => true;
  */

  // âŒ Bad: JIT sees that computation doesn't depend on anything inside loop
  const substr = ctx.get('substr');
  yield () => str.includes(substr);
  // will get optimized to:
  /*
    const $0 = str.includes(substr);
    yield () => $0;
  */

  // âœ… Good: using computed parameters prevents jit from performing any loop optimizations
  yield {
    [0]() {
      return str;
    },

    [1]() {
      return substr;
    },

    bench(str, substr) {
      return do_not_optimize(str.includes(substr));
    },
  };
}).args('substr', ['c']);
```

## License

MIT Â© [evanwashere](https://github.com/evanwashere)
